# Supervised Fine-Tuning Configuration
# Configuration optimisée pour DeepSeek R1 Qwen 12B
# Configuration optimisée pour DeepSeek R1 Qwen 7B

# === Données ===
data_pattern: data/sft_examples/*.jsonl
field: text                        # Champ contenant le texte dans les fichiers JSONL

# === Modèle ===
model_name: deepseekr1-qwen-7b    # DeepSeek R1 Qwen 7B
max_length: 256                    # Réduit pour baisser la conso VRAM
vocab_size: null                   # Auto-détecté depuis le modèle
trust_remote_code: true            # Nécessaire pour DeepSeek

# === Entraînement ===
batch_size: 8                      # Batch size réel (optimisé RTX 3090)
gradient_accumulation_steps: 2     # Équivalent à batch_size 16
epochs: 3                          # Nombre de passes sur les données
learning_rate: 3e-5                # Taux d'apprentissage pour DeepSeek R1 Qwen 12B
weight_decay: 0.01                 # Régularisation L2
warmup_steps: 200                  # Étapes de warmup

# === Optimisation mémoire ===
fp16: true                         # Half-precision sur GPU
gradient_checkpointing: true       # Activé pour réduire VRAM
dataloader_pin_memory: true        # Pin memory pour efficacité GPU
dataloader_num_workers: 8          # Plus de workers avec Ryzen 9 7900
load_in_8bit: true                 # Active quantification 8-bit

# === PEFT LoRA Configuration ===
peft_enable: false                 # Full fine-tuning possible avec RTX 3090
lora_r: 16                         # Rang LoRA (si activé)
lora_alpha: 32                     # Alpha LoRA (si activé)
lora_dropout: 0.05                 # Dropout LoRA (si activé)
lora_target_modules: ["q_proj", "k_proj", "v_proj", "o_proj"] # Modules cibles

# === Logging et évaluation ===
logging_steps: 20                  # Fréquence des logs
evaluation_strategy: steps         # Évaluation par steps
eval_steps: 100                    # Évaluation tous les 100 steps
save_steps: 200                    # Sauvegarde tous les 200 steps
save_total_limit: 3                # Nombre max de checkpoints

# === Métriques ===
metrics:
  - perplexity                     # Perplexité
  - loss                           # Perte d'entraînement
  - bleu                           # Score BLEU (si applicable)

# === Optimiseur ===
optimizer: adamw                   # Optimiseur AdamW
adam_beta1: 0.9                    # Beta1 pour Adam
adam_beta2: 0.999                  # Beta2 pour Adam
adam_epsilon: 1e-8                 # Epsilon pour Adam

# === Scheduler ===
lr_scheduler_type: cosine          # Scheduler cosine
num_warmup_steps: 200              # Steps de warmup
max_grad_norm: 1.0                 # Clipping du gradient

# === Réproductibilité ===
seed: 42                           # Seed pour reproductibilité
data_seed: 42                      # Seed pour données

# === Validation ===
validation_split: 0.1             # 10% des données pour validation
load_best_model_at_end: true       # Charger le meilleur modèle à la fin
metric_for_best_model: eval_loss   # Métrique pour sélection du meilleur modèle
greater_is_better: false           # Plus petit est mieux pour la loss

# === Sorties ===
output_dir: models/sft_finetuned/  # Répertoire de sortie
overwrite_output_dir: true         # Écraser le répertoire existant
report_to: ["tensorboard"]         # Reporting (tensorboard, wandb, etc.)

# === GPU-spécifique RTX 3090 ===
per_device_train_batch_size: 1     # Batch size minimal GPU 24GB
per_device_eval_batch_size: 4      # Batch size éval réduit 