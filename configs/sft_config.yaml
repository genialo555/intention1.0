# AI-Assisted (YYYY-MM-DD): SFT Config pour DeepSeek-R1-Distill-Qwen-7B
# Hardware: (A adapter selon votre matériel)
data_pattern: data/processed/sft_prepared_data.jsonl # S'assurer que cela pointe vers la sortie de prepare_data.py
field: text                       # Le champ dans votre JSONL contenant le texte à entraîner
model_name: /home/genialo/intiasys/models/DeepSeek-R1-Distill-Qwen-7B/ # Modifié pour le chemin local
trust_remote_code: true           # Nécessaire pour certains modèles comme DeepSeek

# Ajuster en fonction de votre GPU et de la taille du modèle
batch_size: 1                     # Les grands modèles nécessitent souvent un petit batch size
gradient_accumulation_steps: 8    # Pour simuler un batch size plus grand (ex: 1*8=8)
epochs: 3                         # Augmenté légèrement pour voir si le modèle apprend quelque chose sur ces quelques exemples
learning_rate: 2e-4               # Learning rate typique pour LoRA, ajuster si besoin (plus haut que pour full SFT)
max_length: 2048                  # Longueur de contexte du modèle Qwen, à vérifier pour cette version distillée

# Paramètres de quantification (optionnel, pour réduire l'utilisation mémoire)
load_in_8bit: true # Nécessaire pour que PEFT soit utile sur des modèles quantifiés
# load_in_4bit: true
# bnb_4bit_quant_type: "nf4"
# bnb_4bit_compute_dtype: "torch.bfloat16"
# bnb_4bit_use_double_quant: true

# --- PEFT LoRA Configuration ---
peft_enable: true
lora_r: 16
lora_alpha: 32
lora_dropout: 0.05
# lora_target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]

logging_steps: 1 # Baissé pour voir plus de logs avec peu de données
evaluation_strategy: "no" # Pas d'évaluation avec si peu de données pour l'instant
eval_steps: 5 # Non pertinent si no evaluation
save_steps: 5  # Sauvegarder après quelques steps pour ce petit test
warmup_steps: 50                  # Adapter en fonction du nombre total de steps
weight_decay: 0.01
seed: 42
fp16: false
gradient_checkpointing: true

# Si votre dataset était sur le Hub Hugging Face (non applicable ici car local)
# dataset_path: "nom_du_dataset_sur_le_hub"
# dataset_config: "config_du_dataset_si_necessaire"
# dataset_split: "train" # ou le split désiré 