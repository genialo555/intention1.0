# Curiosity‚ÄëDriven AI

[![Python](https://img.shields.io/badge/python-3.10+-blue)](https://www.python.org/)  
[![License](https://img.shields.io/badge/license-MIT-green)](LICENSE)  
[![Build Status](https://img.shields.io/badge/CI-passing-brightgreen)](https://github.com/ton-org/curiosity-driven-ai/actions)  

> **‚ö†Ô∏è IMPORTANT** : L'ordre d'entra√Ænement des modules est **critique** pour le fonctionnement du syst√®me. LIMEN doit √™tre entra√Æn√© imm√©diatement apr√®s SFT car il supervise tous les autres modules. Voir [Logique et D√©pendances du Pipeline](#logique-et-d√©pendances-du-pipeline) pour plus de d√©tails.

---

## Table des mati√®res

1. [Vision Initiale et Objectifs Fondamentaux](#vision-initiale-et-objectifs-fondamentaux)  
2. [√âvolution de l'Architecture Technique](#evolution-de-larchitecture-technique)  
3. [Contexte & Motivation](#contexte--motivation)  
4. [Objectifs du Projet](#objectifs-du-projet)  
5. [Architecture Globale](#architecture-globale)  
6. [Principaux Modules](#principaux-modules)  
7. [Module LIMEN : Architecture de l'Intention √âmergente](#module-limen--architecture-de-lintention-√©mergente)  
8. [Fonctionnement du M√©ta‚ÄëContr√¥leur](#fonctionnement-du-m√©ta‚Äëcontr√¥leur)  
9. [Technologies & D√©pendances](#technologies--d√©pendances)  
10. [Installation](#installation)  
11. [Configuration](#configuration)  
12. [Usage & Exemples](#usage--exemples)  
13. [Logique et D√©pendances du Pipeline](#logique-et-d√©pendances-du-pipeline)  
14. [Structure du Projet](#structure-du-projet)  
15. [Tests & Qualit√©](#tests--qualit√©)  
16. [Contribution](#contribution)  
17. [Roadmap & Documentation](#roadmap--documentation)  
18. [Licence](#licence)  

---

## Vision Initiale et Objectifs Fondamentaux

### 1.1 Inspiration & But Ultime
Le projet ¬´ Curiosity-Driven AI ¬ª vise √† concevoir une intelligence artificielle capable d'apprendre et d'explorer son environnement de la m√™me fa√ßon qu'un enfant, guid√©e par une soif de d√©couverte plut√¥t que par des seules r√©compenses extrins√®ques. L'ambition est de d√©passer les limites de la ¬´ Narrow AI ¬ª pour tendre vers une forme d'intelligence plus g√©n√©rale, o√π la curiosit√© intrins√®que motive l'apprentissage continu et la recherche de nouveaux savoirs.

### 1.2 M√©canisme de R√©compense Conceptuel
La premi√®re id√©e fut de cr√©er un syst√®me de ¬´ cartes virtuelles √† collectionner ¬ª : chaque d√©couverte ou progr√®s interne de l'IA g√©n√©rait une nouvelle carte √† ajouter √† sa collection, fournissant une r√©troaction ludique et stimulante pour encourager l'exploration de t√¢ches vari√©es.

### 1.3 Apprentissage Progressif Cible
- **Phase 1** : R√©solution de probl√®mes simples (calculs √©l√©mentaires, √©nigmes logiques) pour √©tablir un socle de comp√©tences structur√©es.
- **Phase 2** : Acquisition naturelle du langage via l'√©tude de livres pour enfants en anglais, afin de ma√Ætriser progressivement la compr√©hension et la g√©n√©ration de texte.
- **Phase 3** : Exploration autonome de concepts plus complexes (sciences, math√©matiques, philosophie) gr√¢ce √† la d√©tection de ¬´ myth√®mes ¬ª, c'est-√†-dire de structures conceptuelles r√©currentes dans diff√©rents domaines.

### 1.4 Notion Cl√© ‚Äì Myth√®mes
Les myth√®mes sont des isomorphismes conceptuels ‚Äì des motifs structurels communs √† plusieurs disciplines. Les rep√©rer permet √† l'IA de transf√©rer profond√©ment ses acquis d'un domaine √† un autre et de d√©velopper une ¬´ m√©ta-curiosit√© ¬ª : comprendre que d√©couvrir un nouveau concept dans un domaine peut √©clairer la r√©solution de probl√®mes dans un autre.

---

## √âvolution de l'Architecture Technique

### 2.1 Mod√®les de Base Consid√©r√©s
- **AlphaGo Zero + MCTS** pour la planification structur√©e et l'exploration d'arbres de d√©cision.  
- **Transformers** (bas√©s sur **DeepSeek R1 Qwen 12B**) servant de colonne vert√©brale pour le langage, le raisonnement supervis√© (SFT) et la g√©n√©ration.  

### 2.2 Apprentissage par Renforcement (RL)
- **Agent Principal** entra√Æn√© avec PPO (Stable-Baselines3 v2+) combinant r√©compenses extrins√®ques et intrins√®ques.  
- **Exploration pour LMs** : tentative d'adapter un policy gradient (inspir√© du diffu-GRPO) aux mod√®les de type diffusion ou masqu√©s pour am√©liorer le raisonnement.  

### 2.3 Modules de Curiosit√© Intrins√®que
- **ICM (Intrinsic Curiosity Module)** : forward model + inverse model ; la r√©compense intrins√®que = erreur du forward model.  
- **RND (Random Network Distillation)** : r√©seau cible fixe et al√©atoire + pr√©dicteur ; r√©compense = erreur de pr√©diction du pr√©dicteur.  

### 2.4 M√©moire et Stabilit√©
- **R√©p√©tition Espac√©e** (SM-2) pour contrer l'oubli catastrophique en apprentissage continu.  
- **Continual Learning** (EWC, replay, adaptateurs LoRA) afin d'ajouter de nouvelles comp√©tences sans effacer les anciennes.  

### 2.5 Architectures Neuronales Sp√©cifiques
- **Transformer¬≤ (CascadeTransformer)** : pipeline coarse-to-fine avec LM fig√© + LM raffineur entra√Ænable (optimisation LoRA).  
- **XNets** : r√©seaux contrastifs (MLP + activations d√©di√©es) pour d√©celer les myth√®mes en comparant embeddings de concepts.  

### 2.6 Orchestration et Contr√¥le
- **M√©ta-Contr√¥leur** (`orchestration/controller.py`) qui choisit dynamiquement quel module activer (SFT, ICM/RND, Transformer¬≤, MCTS/ToT, diffu-GRPO) selon la confiance et la complexit√© de la t√¢che.  
- **Blackboard** : espace cl√©-valeur pour le partage d'informations (chemins de checkpoints, m√©triques).  

### 2.7 Enrichissement et Interaction
- **Ingestion Web** (Selenium) pour la recherche dynamique d'informations.  
- **API Temps-R√©el** (FastAPI/WebSocket) pour piloter entra√Ænement et inf√©rence, et afficher les m√©triques en direct.  
- **Visualisation** sur dashboards (Matplotlib/Seaborn, TensorBoard, W&B) pour suivre pertes, r√©compenses, perplexit√© et embeddings.  

---

## Contexte & Motivation

Les IA classiques apprennent √† optimiser un objectif externe¬†: classification, g√©n√©ration de texte ou d'images. Mais sans **intention propre**, elles manquent de curiosit√©, d'autonomie et peinent √† g√©n√©raliser entre domaines.  
**Curiosity‚ÄëDriven AI** propose un nouveau paradigme¬†: doter l'agent d'une **motivation intrins√®que**, d'un **m√©ta‚Äëcontr√¥leur** et de modules cognitifs (curiosit√©, planification, m√©moire, analogies‚Ä¶) pour qu'il :

- Se fixe ses propres **buts** et les poursuit  
- Explore et apprend de fa√ßon **naturelle** et **continue**  
- **Transf√®re** ses acquis entre disciplines  

Nous nous appuyons sur les avanc√©es¬†: AlphaGo Zero (MCTS), Transformers, reinforcement learning intrins√®que (ICM, RND), mod√®les de diffusion (diffu‚ÄëGRPO), continual learning, myth√®mes (XNets) et apprentissage multimodal.

---

## Objectifs du Projet

1. **Intention**¬†: mod√©liser un processus de but interne, inspir√© des architectures BDI/ACT‚ÄëR et des agents autoteliques (IMGEP).  
2. **Coh√©rence intentionnelle**¬†: LIMEN pour g√©rer les tensions internes et maintenir une intention √©mergente coh√©rente.  
3. **Curiosit√© intrins√®que**¬†: ICM & RND pour pousser l'agent vers l'inconnu.  
4. **Planification**¬†: MCTransformer / Tree‚Äëof‚ÄëThoughts pour la r√©flexion multi‚Äë√©tapes.  
5. **Apprentissage continu**¬†: adaptateurs (LoRA), replay, EWC pour √©viter l'oubli.  
6. **Transdisciplinarit√©**¬†: XNets pour d√©tecter des myth√®mes (isomorphismes conceptuels).  
7. **M√©moire**¬†: r√©p√©tition espac√©e SM‚Äë2 pour ancrer les connaissances.  
8. **√âvolution dynamique**¬†: ingestion Web via Selenium, mise √† jour online.  
9. **Interface**¬†: API FastAPI/WebSocket pour le pilotage en temps r√©el.  
10. **Suivi**¬†: dashboards matplotlib/seaborn pour visualiser progr√®s et intentions.

---

## Architecture Globale

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    MetaLIMEN (Pr√©-Entra√Ænement)               ‚îÇ
‚îÇ              (D√©finition intentions d'apprentissage)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      SFT Guid√© par Intentions                  ‚îÇ
‚îÇ             (Fine-tuning DeepSeek R1 avec guidance)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FullLIMEN (Post-SFT)                        ‚îÇ
‚îÇ              (Intentions raffin√©es avec capacit√©s compl√®tes)    ‚îÇ
‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ     ‚îÇ Validation  ‚îÇ  Phylo      ‚îÇ Conceptual  ‚îÇ Intention   ‚îÇ  ‚îÇ
‚îÇ     ‚îÇ Post-Gen    ‚îÇ Guidance    ‚îÇ   Encoding  ‚îÇ Refinement  ‚îÇ  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îò
      ‚îÇ             ‚îÇ             ‚îÇ             ‚îÇ             ‚îÇ
      ‚ñº             ‚ñº             ‚ñº             ‚ñº             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              üöÄ GROUP THINK PHYLOG√âN√âTIQUE üöÄ                  ‚îÇ
‚îÇ          (Agents Concurrents Collaborant au Niveau Token)      ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇConceptual   ‚îÇ Curiosit√©   ‚îÇ Planif.     ‚îÇ Phylogenetic‚îÇ    ‚îÇ
‚îÇ  ‚îÇTransform.   ‚îÇ (ICM, RND)  ‚îÇ MCTS+ToT    ‚îÇ Myth√®mes    ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ   (T¬≤)      ‚îÇPhylog√©n√©t.  ‚îÇ Conceptuel  ‚îÇ (XNets)     ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ             ‚îÇ             ‚îÇ             ‚îÇ             ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ Token-Level Collaboration avec Shared Phylogenetic Context ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 Conceptual GRPO                                ‚îÇ
‚îÇ       (Optimisation phylog√©n√©tique dans l'espace conceptuel)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   Interface & Monitoring                       ‚îÇ
‚îÇ                (API WebSocket/REST, Dashboards)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Points cl√©s de l'architecture r√©volutionnaire :

1. **MetaLIMEN pr√©liminaire** : D√©finit les intentions d'apprentissage avant toute base linguistique
2. **SFT guid√© par intentions** : Construction de la fondation linguistique orient√©e par les objectifs conceptuels  
3. **FullLIMEN post-SFT** : Raffinement des intentions avec capacit√©s linguistiques compl√®tes
4. **üöÄ Group Think phylog√©n√©tique** : **Agents concurrents collaborant au niveau token** - R√©volution architecturale
5. **Optimisation conceptuelle** : GRPO dans l'espace des concepts plut√¥t que tokens

### üöÄ R√©volution Group Think Phylog√©n√©tique

Notre syst√®me int√®gre l'architecture r√©volutionnaire [Group Think](https://arxiv.org/abs/2505.11107) adapt√©e √† l'espace phylog√©n√©tique conceptuel. Cette approche transforme nos modules en agents concurrents qui :

- **Collaborent au niveau token** avec shared visibility phylog√©n√©tique
- **R√©duisent la latence de 50%+** vs approche s√©quentielle traditionnelle
- **Optimisent l'utilisation GPU** avec edge inference efficace
- **G√©n√®rent une qualit√© √©mergente sup√©rieure** gr√¢ce √† la collaboration

**Documentation compl√®te** : [Architecture Group Think Phylog√©n√©tique](docs/architecture/group_think_integration.md)

**B√©n√©fices r√©volutionnaires** :
- ‚úÖ **Latence r√©duite** : ~1-2s vs ~5-10s (pipeline s√©quentiel)
- ‚úÖ **Qualit√© √©mergente** : +30% vs agent unique
- ‚úÖ **Utilisation GPU** : >90% avec batch sizes faibles
- ‚úÖ **Architecture agent formalis√©e** selon standards industriels

---

## Principaux Modules

1. **SFT (Supervised Fine‚ÄëTuning)**  
   - Initie l'intuition de raisonnement sur GSM8K, MATH, etc.  
2. **Transformer¬≤**  
   - Architecture en cascade : un second Transformer affine la sortie du premier.  
3. **Curiosit√© Intrins√®que**  
   - ICM (Pathak et al. 2017) + RND pour reward de surprise.  
   - IMGEP pour g√©n√©ration autonome de buts.  
4. **Planification MCTS+Transformer**  
   - MCTransformer ou Tree‚Äëof‚ÄëThoughts pour explorer plusieurs cha√Ænes de pens√©e avant r√©ponse.  
5. **Spaced Repetition**  
   - Algorithme SM‚Äë2 pour scheduler des r√©visions sur BabyLM (10 M ‚Üí 100 M mots).  
6. **Continual Learning**  
   - Adaptateurs (LoRA), replay buffer, EWC, Transformer‚ÄëXL online pour apprentissage en flux continu.  
7. **XNets & Myth√®mes**  
   - D√©tection d'isomorphismes conceptuels entre disciplines via blocs lin√©aires + Softplus.  
8. **diffu‚ÄëGRPO**  
   - RL pour mod√®les de diffusion masqu√©e (one‚Äëstep policy gradient + prompt masking).  
9. **Ingestion Web**  
   - Selenium + webdriver‚Äëmanager pour r√©cup√©rer des informations en ligne.  
10. **API Temps R√©el**  
    - FastAPI + WebSocket pour envoyer prompts, recevoir √©tats, ajuster hyperparam√®tres.  
11. **Dashboards**  
    - matplotlib & seaborn pour visualiser m√©triques, confiance, r√©compenses, roadmap.
12. **LIMEN (Latent Intent Meta-Emergent Nexus)**
    - Module de coh√©rence intentionnelle g√©rant les tensions internes entre modules
    - Combine LIDM, coordination multi-agent, MRKL et monologue int√©rieur
    - Permet le refus r√©flexif et le silence raisonn√© quand l'intention est en conflit

---

## Module LIMEN : Architecture de l'Intention √âmergente

### Vue d'ensemble
LIMEN (Latent Intent Meta-Emergent Nexus) constitue l'organe de coh√©rence intentionnelle de l'agent, g√©rant les tensions et contradictions internes entre modules pour maintenir une intention coh√©rente mais dynamique.

### Briques architecturales int√©gr√©es

#### 1. LIDM (Latent Intention Dialogue Model)
**Ce qu'on garde :**
- Repr√©sentation discr√®te de l'intention comme variable latente
- Capacit√© √† moduler la g√©n√©ration via un vecteur d'intention choisi

**Ce qu'on ajoute :**
- Intention non supervis√©e issue de tensions internes (pas juste cluster d'√©tiquettes)
- Cycle r√©flexif o√π l'intention peut √™tre refus√©e par d'autres modules

#### 2. Multi-Agent Intention Coordination (MARL)
**Ce qu'on garde :**
- Consensus / divergence entre modules sp√©cialis√©s
- Propagation dynamique de l'intention entre modules
- Accords √©mergents

**Ce qu'on ajoute :**
- Ces "agents internes" sont des parties d'un m√™me esprit
- Modulateur central qui peut inhiber une intention majoritaire (‚â† juste voter)

#### 3. MRKL Systems (Modular Reasoning & Knowledge)
**Ce qu'on garde :**
- Structure modulaire raisonnement/langage/m√©moire
- S√©lection dynamique de modules selon contexte

**Ce qu'on ajoute :**
- M√©moire intentionnelle flottante (non seulement knowledge)
- Modules en tension, pas toujours align√©s ‚Äî friction contr√¥l√©e

#### 4. ICL-inspired "Inner Monologue"
**Ce qu'on garde :**
- Capacit√© √† raisonner avant de r√©pondre
- Auto-√©valuation implicite de l'action √† prendre

**Ce qu'on ajoute :**
- Logique de "silence raisonn√©" : l'agent peut ne pas r√©pondre si son LIMEN est en d√©saccord profond
- Trace de doute : "je pense mais je ne suis pas s√ªr, donc je retiens"

### Composants fonctionnels de LIMEN

| √âl√©ment | Fonction centrale |
|---------|-------------------|
| **Tenseur latent** | Porte l'intention du moment (dynamiquement mis √† jour) |
| **Tension evaluator** | Compare intention, contexte, m√©moire, contradiction |
| **D√©sactivateur** | Peut annuler, bloquer, ou retarder une r√©ponse |
| **Inhibiteur social** | R√©agit au consensus (GroupThink) mais peut refuser d'y adh√©rer |
| **Moteur d'apprentissage local** | Apprend quand une intention m√®ne au bon type de rupture |

### Int√©gration avec le M√©ta-Contr√¥leur

LIMEN s'interface directement avec le m√©ta-contr√¥leur existant, ajoutant une couche de validation intentionnelle :
- Avant l'activation d'un module, LIMEN √©value la coh√©rence de l'intention
- En cas de conflit profond, LIMEN peut forcer un mode "silence" ou "exploration alternative"
- Les m√©triques de tension interne sont ajout√©es au blackboard pour analyse

### Configuration LIMEN

Un nouveau fichier `configs/limen_config.yaml` permet de param√©trer :
```yaml
# Configuration LIMEN
latent_dim: 128              # Dimension du tenseur d'intention latente
tension_threshold: 0.7       # Seuil de tension pour d√©clencher l'inhibition
consensus_weight: 0.3        # Poids du consensus vs individualit√©
doubt_trace_memory: 100      # Nombre d'√©tats de doute √† conserver
learning_rate: 1e-4          # Taux d'apprentissage du moteur local
update_frequency: 10         # Fr√©quence de mise √† jour du tenseur latent
module_weights:              # Poids des diff√©rents modules dans les d√©cisions
  transformer: 0.3
  curiosity: 0.2
  planning: 0.2
  memory: 0.3
silence_mode_threshold: 0.85 # Seuil de tension pour activer le mode silence
```

---

## Fonctionnement du M√©ta‚ÄëContr√¥leur

Le m√©ta‚Äëcontr√¥leur (`orchestration/controller.py`) inspecte en continu :

- **Confiance** du mod√®le (entropie, variance)  
- **Complexit√©** du prompt (longueur, motifs d√©tect√©s)  
- **Flux de donn√©es** (nouvelles entr√©es, r√©sultat d'ICM)  
- **Coh√©rence intentionnelle** (via LIMEN) : tensions internes, contradictions

Processus de d√©cision enrichi par LIMEN :

1. Analyse initiale de la t√¢che (confiance, complexit√©)
2. **Validation intentionnelle par LIMEN** :
   - √âvaluation de la coh√©rence entre l'intention latente et l'action propos√©e
   - D√©tection des tensions internes entre modules
   - D√©cision : proc√©der, modifier l'approche, ou silence raisonn√©
3. Si validation positive, activation selon les seuils (`configs/network.yaml`) :
   - **Transformer** seul  
   - **Curiosit√© (ICM/RND)**  
   - **Transformer¬≤**  
   - **MCTransformer / ToT**  
   - **Continual Learning**  
4. Si tension d√©tect√©e par LIMEN :
   - Mode **exploration alternative** : essayer une approche diff√©rente
   - Mode **silence** : ne pas r√©pondre tant que la coh√©rence n'est pas retrouv√©e
   - Mode **r√©flexion approfondie** : activer plusieurs modules pour r√©soudre le conflit

Il consigne chaque ¬´ √©tat ‚Üí intention ‚Üí d√©cision LIMEN ‚Üí action ‚Üí r√©compense ¬ª dans un **blackboard** partag√© pour analyse et replay.

---

## Technologies & D√©pendances

- **Langage :** Python 3.10+  
- **Mod√©lisation & RL :** PyTorch, Stable‚ÄëBaselines3, Transformers  
- **Diffusion RL :** impl√©mentation custom diffu‚ÄëGRPO  
- **Planification :** MCTS, custom MCTransformer  
- **Continual Learning :** Avalanche (ou accelerate), LoRA, EWC  
- **Web Scraping :** Selenium, webdriver‚Äëmanager  
- **API & Temps R√©el :** FastAPI, Uvicorn, WebSockets, Pydantic  
- **Visualisation :** matplotlib, seaborn, TensorBoard, W&B  
- **Qualit√© & CI :** black, flake8, markdownlint, GitHub Actions  
- **Versioning Donn√©es :** DVC / Git LFS  

---

## Installation

```bash
# Cloner le d√©p√¥t
git clone https://github.com/ton‚Äëorg/curiosity‚Äëdriven‚Äëai.git
cd curiosity‚Äëdriven‚Äëai

# Environnement virtuel
python3.10 -m venv .venv
source .venv/bin/activate

# Installer les d√©pendances
pip install -r requirements.txt

### Configuration

Adapt the following configuration files before each training run:

* **configs/sft_config.yaml** (Supervised Fine-Tuning):
  ```yaml
  # Example optimized config for RTX4050
  data_pattern: data/sft_examples/*.jsonl
  field: text
  model_name: deepseekr1-qwen-12b    # DeepSeek R1 Qwen 12B
  batch_size: 4                  # actual batch size
  gradient_accumulation_steps: 4 # equivalent to batch_size 16
  epochs: 3                      # multiple passes to converge
  learning_rate: 3e-5            # lower LR for DeepSeek R1 Qwen 12B
  max_length: 512
  logging_steps: 20
  evaluation_strategy: steps
  eval_steps: 100
  save_steps: 200
  warmup_steps: 200
  weight_decay: 0.01
  seed: 42
  fp16: true                     # half-precision on GPU
  gradient_checkpointing: true   # reduce activation memory
  ```

* **configs/network.yaml**: thresholds for trust/complexity, hyperparameters for Transformer¬≤, XNets.
* **configs/grpo_config.yaml**: masking rate, reward weights for diffu‚ÄëGRPO
  ```yaml
  # Default diffu‚ÄëGRPO config
  model_path: models/sft_finetuned/latest.pt  # Path to pretrained SFT checkpoint
  mask_rate: 0.15           # Proportion of tokens to mask per step
  reward_weight: 1.0        # Weight for reward computation
  use_log_ratio: false      # Use log-ratio between unmasked/masked loss if true
  timesteps: 1000           # Number of diffusion+policy gradient steps
  logging_steps: 100        # Interval for logging progress
  save_steps: 100           # Steps between checkpoint saves
  learning_rate: 5e-5       # Learning rate for policy optimizer
  seed: 42                  # Random seed
  seq_len: 16               # Sequence length for input
  batch_size: 2             # Batch size during training
  ```
* **configs/icm_config.yaml** (Intrinsic Curiosity Module - ICM):
  ```yaml
  # Default ICM config
  env: CartPole-v1          # Gym environment name
  timesteps: 1000           # Number of timesteps to run the agent
  logging_steps: 100        # Interval for logging progress
  seed: 42                  # Random seed for reproducibility
  lr: 1e-3                  # Learning rate for ICM optimizer
  save_steps: 100           # Steps between model checkpoint saves
  ```
* **configs/rnd_config.yaml** (Random Network Distillation - RND):
  ```yaml
  # Default RND config
  env: CartPole-v1          # Gym environment name
  timesteps: 1000           # Number of timesteps to run the placeholder agent
  logging_steps: 100        # Interval for logging progress
  seed: 42                  # Random seed for reproducibility
  # Add lr, save_steps, and other hyperparameters when implementing full RND module
  ```
* **configs/transformer2_config.yaml** (Transformer¬≤ placeholder config):
  ```yaml
  # Transformer¬≤ placeholder config
  model_name: deepseekr1-qwen-12b    # DeepSeek R1 Qwen 12B
  seq_len: 16                 # Sequence length for input
  batch_size: 2               # Batch size for placeholder training
  timesteps: 10               # Number of training steps on random token data
  learning_rate: 5e-5         # Learning rate for refiner optimizer
  logging_steps: 1            # Log interval
  save_steps: 5               # Checkpoint save interval
  seed: 42                    # Seed for reproducibility
  peft_enable: false          # Enable LoRA adapters via PEFT (requires `peft` package)
  peft_r: 8                   # LoRA rank
  peft_alpha: 32              # LoRA scaling factor
  peft_dropout: 0.05          # LoRA dropout rate
  ```
* **configs/limen_config.yaml** (Latent Intent Meta-Emergent Nexus):
  ```yaml
  # Configuration LIMEN
  latent_dim: 128              # Dimension du tenseur d'intention latente
  tension_threshold: 0.7       # Seuil de tension pour d√©clencher l'inhibition
  consensus_weight: 0.3        # Poids du consensus vs individualit√©
  doubt_trace_memory: 100      # Nombre d'√©tats de doute √† conserver
  learning_rate: 1e-4          # Taux d'apprentissage du moteur local
  update_frequency: 10         # Fr√©quence de mise √† jour du tenseur latent
  module_weights:              # Poids des diff√©rents modules dans les d√©cisions
    transformer: 0.3
    curiosity: 0.2
    planning: 0.2
    memory: 0.3
  silence_mode_threshold: 0.85 # Seuil de tension pour activer le mode silence
  ```
* **.env** (optionnel) : Selenium credentials, API tokens.

Adaptez ces fichiers selon votre mat√©riel et vos jeux de donn√©es.

1. Entra√Ænement SFT

```bash
python scripts/train_sft.py \
  --config configs/sft_config.yaml \
  --output models/sft_finetuned/
```

2. LIMEN - Module d'Intention √âmergente (superviseur)

```bash
python scripts/train_limen.py \
  --config configs/limen_config.yaml \
  --sft_checkpoint models/sft_finetuned/latest.pt \
  --output models/limen/
```

3. Intrinsic Curiosity Module (ICM) - Sous supervision LIMEN

```bash
python scripts/train_icm.py \
  --config configs/icm_config.yaml \
  --limen_checkpoint models/limen/latest.pt \
  --output models/icm/
```

4. Random Network Distillation (RND) - Sous supervision LIMEN

```bash
python scripts/train_rnd.py \
  --config configs/rnd_config.yaml \
  --limen_checkpoint models/limen/latest.pt \
  --output models/rnd/
```

5. Transformer¬≤ - Raisonnement avanc√©

```bash
python scripts/train_mcts_tf.py \
  --config configs/transformer2_config.yaml \
  --limen_checkpoint models/limen/latest.pt \
  --output models/mcts_transformer/
```

6. diffu-GRPO (Renforcement avec syst√®me int√©gr√©)

```bash
python scripts/train_diffu_grpo.py \
  --config configs/grpo_config.yaml \
  --limen_checkpoint models/limen/latest.pt \
  --output models/diffu_grpo_from_sft/
```

7. Lancement de l'API Temps-R√©el & Dashboards
```bash
uvicorn realtime.server:app --reload
```

Cette configuration optimis√©e pour RTX 3090 garantit une utilisation efficace des 24GB de VRAM disponibles.

8. Rapport Hebdomadaire

python scripts/report_weekly.py
# g√©n√®re un rapport Markdown/HTML dans visualization/reports/

Structure du Projet

curiosity_ai_project/
‚îÇ
‚îú‚îÄ‚îÄ data/                    # jeux de donn√©es segment√©s par phase
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ diffusion_base/
‚îÇ   ‚îú‚îÄ‚îÄ sft_finetuned/
‚îÇ   ‚îî‚îÄ‚îÄ diffu_grpo/
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ icm/
‚îÇ   ‚îú‚îÄ‚îÄ rnd/
‚îÇ   ‚îú‚îÄ‚îÄ xnet/
‚îÇ   ‚îú‚îÄ‚îÄ spaced_repetition/
‚îÇ   ‚îú‚îÄ‚îÄ continual_learning/
‚îÇ   ‚îú‚îÄ‚îÄ transformer_squared/
‚îÇ   ‚îî‚îÄ‚îÄ limen/
‚îú‚îÄ‚îÄ orchestration/
‚îÇ   ‚îú‚îÄ‚îÄ controller.py
‚îÇ   ‚îî‚îÄ‚îÄ mcts_transformer/
‚îú‚îÄ‚îÄ ingestion/
‚îÇ   ‚îî‚îÄ‚îÄ web/
‚îú‚îÄ‚îÄ realtime/
‚îÇ   ‚îú‚îÄ‚îÄ server.py
‚îÇ   ‚îú‚îÄ‚îÄ api.py
‚îÇ   ‚îî‚îÄ‚îÄ client_example.py
‚îú‚îÄ‚îÄ visualization/
‚îÇ   ‚îî‚îÄ‚îÄ reports/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ train_*.py
‚îÇ   ‚îî‚îÄ‚îÄ report_weekly.py
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îî‚îÄ‚îÄ *.yaml
‚îú‚îÄ‚îÄ docs/
‚îú‚îÄ‚îÄ .cursor/rules/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ ROADMAP.md
‚îî‚îÄ‚îÄ requirements.txt

Tests & Qualit√©

    Unitaires : pytest tests/unit/

    Int√©gration : pytest tests/integration/

    Lint : black --check ., flake8 ., markdownlint docs/

    CI : GitHub Actions ex√©cute l'ensemble √† chaque PR.

Contribution

    Forker le d√©p√¥t & cr√©er une branche th√©matique.

    Respecter les Cursor Rules (structure, docstrings, mise √† jour README/ROADMAP).

    Ajouter tests unitaires pour tout nouveau code.

    Soumettre un Pull Request d√©taillant vos changements.

Voir CONTRIBUTING.md pour plus de d√©tails.
Roadmap & Documentation

    La Roadmap d√©taill√©e se trouve dans ROADMAP.md.

    Consultez docs/network_design.md pour les sch√©mas d'architecture et docs/api_examples.md pour les exemples d'appels.

    Les r√®gles d'√©dition sont dans .cursor/rules/.

## Usage & Exemples

### 5. Pipeline recommand√©
Assurez-vous d'avoir configur√© votre GPU (voir section ¬´ Mat√©riel & Configuration GPU ¬ª), puis suivez ces √©tapes :

1. Data Ingestion & Pr√©-traitement
   ```bash
   python scripts/prepare_data.py \
     --input data/raw_prompts.jsonl \
     --output data/processed/
   ```
2. Supervised Fine-Tuning (SFT)
   ```bash
   python scripts/train_sft.py \
     --config configs/sft_config.yaml \
     --output models/sft_finetuned/
   ```
3. LIMEN - Initialisation du superviseur d'intentions
   ```bash
   python scripts/train_limen.py \
     --config configs/limen_config.yaml \
     --sft_checkpoint models/sft_finetuned/latest.pt \
     --output models/limen/
   ```
4. (Optionnel) Entra√Ænement des modules de curiosit√© sous supervision LIMEN
   ```bash
   # ICM
   python scripts/train_icm.py \
     --config configs/icm_config.yaml \
     --limen_checkpoint models/limen/latest.pt \
     --output models/icm/
   
   # RND
   python scripts/train_rnd.py \
     --config configs/rnd_config.yaml \
     --limen_checkpoint models/limen/latest.pt \
     --output models/rnd/
   ```
5. diffu-GRPO (RL avec syst√®me complet int√©gr√©)
   ```bash
   python scripts/train_diffu_grpo.py \
     --config configs/grpo_config.yaml \
     --limen_checkpoint models/limen/latest.pt \
     --output models/diffu_grpo_from_sft/
   ```
6. √âvaluation finale & d√©ploiement
   ```bash
   python scripts/evaluate_full_system.py \
     --model models/diffu_grpo_from_sft/final_model \
     --limen models/limen/latest.pt \
     --data data/processed/test.jsonl
   ```
7. API Temps-R√©el & Dashboards avec syst√®me complet
   ```bash
   uvicorn realtime.server:app --reload
   ```
Cette organisation assure que LIMEN supervise tous les autres modules d√®s leur entra√Ænement.

## Mat√©riel & Configuration

### Sp√©cifications syst√®me recommand√©es
- **GPU** : NVIDIA GeForce RTX 3090 (24GB VRAM)
- **CPU** : AMD Ryzen 9 7900 (12-core/24-thread)
- **RAM** : 64GB DDR4/DDR5
- **Stockage** : SSD NVMe 1TB+ pour datasets et mod√®les

Le pipeline exploite cette configuration puissante pour un entra√Ænement efficace des mod√®les DeepSeek R1 Qwen 12B.

### Configuration GPU
Avant chaque ex√©cution d'entra√Ænement, configurez votre GPU :
```bash
export CUDA_DEVICE_ORDER=PCI_BUS_ID
export CUDA_VISIBLE_DEVICES=0  # RTX 3090
sudo nvidia-smi --gpu-reset -i 0  # R√©initialiser si n√©cessaire
nvidia-smi -pm 1                 # Mode performance
```

### Pipeline complet d'entra√Ænement

Pour d√©marrer de z√©ro et couvrir toutes les phases avec l'approche phylog√©n√©tique conceptelle :

1. Configuration GPU
```bash
export CUDA_DEVICE_ORDER=PCI_BUS_ID
export CUDA_VISIBLE_DEVICES=0  # RTX 3090
sudo nvidia-smi --gpu-reset -i 0  # reset si bloqu√©
nvidia-smi -pm 1                 # mode performance
```

2. Pr√©-traitement des donn√©es conceptuelles
```bash
python scripts/prepare_conceptual_data.py \
  --domains "physics,biology,economics,psychology" \
  --output data/conceptual_corpus/
```

3. **MetaLIMEN** - D√©finition des intentions d'apprentissage
```bash
python scripts/train_meta_limen.py \
  --config configs/meta_limen_config.yaml \
  --domains data/conceptual_corpus/ \
  --output models/meta_limen/
```

4. **SFT Guid√© par Intentions** - Base linguistique intentionnelle
```bash
python scripts/train_intentional_sft.py \
  --config configs/sft_config.yaml \
  --meta_limen_checkpoint models/meta_limen/latest.pt \
  --output models/sft_finetuned/
```

5. **FullLIMEN** - Intentions sophistiqu√©es post-SFT
```bash
python scripts/train_full_limen.py \
  --config configs/limen_config.yaml \
  --sft_checkpoint models/sft_finetuned/latest.pt \
  --meta_intentions models/meta_limen/intentions.pt \
  --output models/full_limen/
```

6. **Conceptual ICM** - Curiosit√© phylog√©n√©tique conceptelle
```bash
python scripts/train_conceptual_icm.py \
  --config configs/icm_config.yaml \
  --full_limen_checkpoint models/full_limen/latest.pt \
  --output models/conceptual_icm/
```

7. **Conceptual RND** - Nouveaut√© dans l'espace conceptuel
```bash
python scripts/train_conceptual_rnd.py \
  --config configs/rnd_config.yaml \
  --full_limen_checkpoint models/full_limen/latest.pt \
  --output models/conceptual_rnd/
```

8. **Transformer¬≤ Intentionnel** - Raffinement guid√© phylog√©n√©tiquement
```bash
python scripts/train_intentional_transformer2.py \
  --config configs/transformer2_config.yaml \
  --full_limen_checkpoint models/full_limen/latest.pt \
  --output models/intentional_transformer_squared/
```

9. **MCTS Conceptuel** - Planification dans l'espace phylog√©n√©tique
```bash
python scripts/train_conceptual_mcts.py \
  --config configs/mcts_conceptual_config.yaml \
  --full_limen_checkpoint models/full_limen/latest.pt \
  --output models/conceptual_mcts/
```

10. **Phylogenetic Myth√®mes** - D√©tection d'homologies conceptuelles
```bash
python scripts/train_phylogenetic_mythemes.py \
  --config configs/mythemes_config.yaml \
  --full_limen_checkpoint models/full_limen/latest.pt \
  --output models/phylogenetic_mythemes/
```

11. **Conceptual GRPO** - Optimisation phylog√©n√©tique globale
```bash
python scripts/train_conceptual_grpo.py \
  --config configs/conceptual_grpo_config.yaml \
  --full_limen_checkpoint models/full_limen/latest.pt \
  --conceptual_modules models/conceptual_*/ \
  --output models/conceptual_grpo/
```

12. **√âvaluation Phylog√©n√©tique Compl√®te**
```bash
python scripts/evaluate_phylogenetic_system.py \
  --model models/conceptual_grpo/final_model \
  --full_limen models/full_limen/latest.pt \
  --validation_type "phylogenetic_bootstrap" \
  --data data/conceptual_corpus/test/
```

13. **API Phylog√©n√©tique Temps-R√©el**
```bash
uvicorn realtime.conceptual_server:app --reload \
  --env FULL_LIMEN_MODEL=models/full_limen/latest.pt \
  --env CONCEPTUAL_SYSTEM=models/conceptual_grpo/final_model
```

### Notes importantes sur l'ordre phylog√©n√©tique :
- **MetaLIMEN d'abord** : D√©finit les intentions d'apprentissage pr√©-linguistiques
- **SFT guid√© ensuite** : Construit la base linguistique selon les intentions
- **FullLIMEN post-SFT** : Raffine les intentions avec capacit√©s linguistiques compl√®tes
- **Modules conceptuels** : Travaillent dans l'espace phylog√©n√©tique sous guidance FullLIMEN
- **GRPO conceptuel en dernier** : Optimise le syst√®me int√©gr√© dans l'espace conceptuel

Cette approche r√©volutionnaire transforme l'apprentissage en **construction phylog√©n√©tique intentionnelle** o√π chaque √©tape est guid√©e par la coh√©rence conceptuelle et l'intention √©mergente.

---

## Logique et D√©pendances du Pipeline

### Pourquoi ce nouvel ordre r√©volutionnaire ?

L'inspiration de l'[article Nature Communications](https://www.nature.com/articles/s41467-021-22073-8) r√©v√®le que **l'intention guide la construction** dans les syst√®mes phylog√©n√©tiques. Notre pipeline hybride r√©sout le paradoxe bootstrap :

```
MetaLIMEN ‚Üí SFT_Guided ‚Üí FullLIMEN ‚Üí [ICM, RND, Transformer¬≤, MCTS] ‚Üí diffu-GRPO ‚Üí API
     ‚Üì           ‚Üì           ‚Üì              ‚Üì                            ‚Üì         ‚Üì
Meta-Intent  Intentional  Complete    Conceptual                Phylogenetic   Interface
Definition   Learning     Intentions  Modules                   Optimization
```

#### 1. **MetaLIMEN** - Intentions Pr√©-Linguistiques
- **D√©finit les objectifs d'apprentissage** avant toute compr√©hension complexe
- Utilise des embeddings simples (Word2Vec) pour intentions de haut niveau
- √âtablit un espace m√©ta-intentionnel pour guider l'apprentissage
- **R√©sout le bootstrap** : intentions simples ‚Üí capacit√©s complexes

#### 2. **SFT Guid√©** - Apprentissage Intentionnel
- **Construction fondation linguistique** orient√©e par les m√©ta-intentions
- Curriculum bas√© sur les intentions phylog√©n√©tiques conceptuelles
- Filtrage et pond√©ration des donn√©es selon les objectifs d√©finis
- **Base solide** avec direction intentionnelle int√©gr√©e

#### 3. **FullLIMEN** - Raffinement Intentionnel
- **Intentions compl√®tes** utilisant les capacit√©s linguistiques acquises
- Encodage sophistiqu√© dans l'espace phylog√©n√©tique conceptuel
- Validation post-g√©n√©ration et guidance des modules avanc√©s
- **Superviseur mature** avec compr√©hension linguistique compl√®te

#### 4. **Modules Phylog√©n√©tiques** - Exploration Conceptuelle
- **ICM/RND conceptuel** : Curiosit√© dans l'espace phylog√©n√©tique des concepts
- **Transformer¬≤ intentionnel** : Raffinement guid√© par intentions phylog√©n√©tiques
- **MCTS conceptuel** : Planification dans l'arbre des concepts
- **XNets/Myth√®mes** : D√©tection d'homologies conceptuelles inter-domaines

#### 5. **Conceptual GRPO** - Optimisation Phylog√©n√©tique
- **Optimisation dans l'espace conceptuel** plut√¥t que l'espace des tokens
- Policy gradient guid√© par vraisemblance phylog√©n√©tique conceptuelle
- Int√©gration des signaux de curiosit√©, planning et intentions
- **Optimisation globale** du syst√®me conceptuel int√©gr√©

### Avantages de cette Approche Hybride

‚úÖ **Coh√©rence intentionnelle** : L'intention guide tout le processus d√®s le d√©but  
‚úÖ **R√©solution bootstrap** : MetaLIMEN simple ‚Üí FullLIMEN sophistiqu√©  
‚úÖ **Base scientifique** : Inspir√©e des m√©thodes phylog√©n√©tiques valid√©es  
‚úÖ **Architecture unifi√©e** : Tous les modules dans l'espace conceptuel phylog√©n√©tique  
‚úÖ **Optimisation coh√©rente** : GRPO dans l'espace des concepts  

### Cons√©quences d'un retour √† l'ancien ordre :

‚ùå **Si SFT avant MetaLIMEN** : Apprentissage sans direction intentionnelle claire  
‚ùå **Si pas de MetaLIMEN** : Impossible de d√©finir les intentions d'apprentissage  
‚ùå **Si FullLIMEN avant SFT** : Paradoxe bootstrap non r√©solu  
‚ùå **Si modules avant FullLIMEN** : Pas de guidance intentionnelle sophistiqu√©e

‚úÖ **Ordre optimal** : MetaLIMEN ‚Üí SFT ‚Üí FullLIMEN ‚Üí Modules ‚Üí GRPO garantit coh√©rence intentionnelle et optimisation phylog√©n√©tique conceptuelle

