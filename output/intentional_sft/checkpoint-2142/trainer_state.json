{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 100,
  "global_step": 2142,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.028011204481792718,
      "grad_norm": 0.18430818617343903,
      "learning_rate": 2.8500000000000002e-06,
      "loss": 3.1318,
      "step": 20
    },
    {
      "epoch": 0.056022408963585436,
      "grad_norm": 0.24992452561855316,
      "learning_rate": 5.850000000000001e-06,
      "loss": 2.9726,
      "step": 40
    },
    {
      "epoch": 0.08403361344537816,
      "grad_norm": 0.2464396357536316,
      "learning_rate": 8.85e-06,
      "loss": 3.008,
      "step": 60
    },
    {
      "epoch": 0.11204481792717087,
      "grad_norm": 0.31807106733322144,
      "learning_rate": 1.185e-05,
      "loss": 2.9671,
      "step": 80
    },
    {
      "epoch": 0.1400560224089636,
      "grad_norm": 0.3917706608772278,
      "learning_rate": 1.485e-05,
      "loss": 3.014,
      "step": 100
    },
    {
      "epoch": 0.1400560224089636,
      "eval_loss": 2.9554762840270996,
      "eval_runtime": 4.1586,
      "eval_samples_per_second": 19.237,
      "eval_steps_per_second": 2.405,
      "step": 100
    },
    {
      "epoch": 0.16806722689075632,
      "grad_norm": 0.47193774580955505,
      "learning_rate": 1.785e-05,
      "loss": 3.02,
      "step": 120
    },
    {
      "epoch": 0.19607843137254902,
      "grad_norm": 0.5394734740257263,
      "learning_rate": 2.085e-05,
      "loss": 2.8247,
      "step": 140
    },
    {
      "epoch": 0.22408963585434175,
      "grad_norm": 0.5505515933036804,
      "learning_rate": 2.385e-05,
      "loss": 2.7567,
      "step": 160
    },
    {
      "epoch": 0.25210084033613445,
      "grad_norm": 1.0471594333648682,
      "learning_rate": 2.6850000000000002e-05,
      "loss": 2.6967,
      "step": 180
    },
    {
      "epoch": 0.2801120448179272,
      "grad_norm": 1.0625081062316895,
      "learning_rate": 2.985e-05,
      "loss": 2.5241,
      "step": 200
    },
    {
      "epoch": 0.2801120448179272,
      "eval_loss": 2.366065263748169,
      "eval_runtime": 4.2207,
      "eval_samples_per_second": 18.954,
      "eval_steps_per_second": 2.369,
      "step": 200
    },
    {
      "epoch": 0.3081232492997199,
      "grad_norm": 1.7492353916168213,
      "learning_rate": 2.9706488156539652e-05,
      "loss": 2.4028,
      "step": 220
    },
    {
      "epoch": 0.33613445378151263,
      "grad_norm": 1.4114845991134644,
      "learning_rate": 2.939752832131823e-05,
      "loss": 2.103,
      "step": 240
    },
    {
      "epoch": 0.3641456582633053,
      "grad_norm": 1.054993987083435,
      "learning_rate": 2.908856848609681e-05,
      "loss": 2.2073,
      "step": 260
    },
    {
      "epoch": 0.39215686274509803,
      "grad_norm": 1.8827705383300781,
      "learning_rate": 2.8779608650875387e-05,
      "loss": 1.7281,
      "step": 280
    },
    {
      "epoch": 0.42016806722689076,
      "grad_norm": 1.4149898290634155,
      "learning_rate": 2.8470648815653967e-05,
      "loss": 1.7757,
      "step": 300
    },
    {
      "epoch": 0.42016806722689076,
      "eval_loss": 1.5410149097442627,
      "eval_runtime": 4.8572,
      "eval_samples_per_second": 16.47,
      "eval_steps_per_second": 2.059,
      "step": 300
    },
    {
      "epoch": 0.4481792717086835,
      "grad_norm": 2.4915475845336914,
      "learning_rate": 2.8161688980432544e-05,
      "loss": 1.5929,
      "step": 320
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 1.5683857202529907,
      "learning_rate": 2.785272914521112e-05,
      "loss": 1.5662,
      "step": 340
    },
    {
      "epoch": 0.5042016806722689,
      "grad_norm": 1.922154188156128,
      "learning_rate": 2.7543769309989702e-05,
      "loss": 1.5516,
      "step": 360
    },
    {
      "epoch": 0.5322128851540616,
      "grad_norm": 1.2899993658065796,
      "learning_rate": 2.723480947476828e-05,
      "loss": 1.5383,
      "step": 380
    },
    {
      "epoch": 0.5602240896358543,
      "grad_norm": 1.4825767278671265,
      "learning_rate": 2.692584963954686e-05,
      "loss": 1.4012,
      "step": 400
    },
    {
      "epoch": 0.5602240896358543,
      "eval_loss": 1.187685251235962,
      "eval_runtime": 4.9508,
      "eval_samples_per_second": 16.159,
      "eval_steps_per_second": 2.02,
      "step": 400
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 1.315618634223938,
      "learning_rate": 2.6616889804325437e-05,
      "loss": 1.1718,
      "step": 420
    },
    {
      "epoch": 0.6162464985994398,
      "grad_norm": 2.369220733642578,
      "learning_rate": 2.6307929969104017e-05,
      "loss": 1.0866,
      "step": 440
    },
    {
      "epoch": 0.6442577030812325,
      "grad_norm": 2.1779932975769043,
      "learning_rate": 2.5998970133882594e-05,
      "loss": 1.1484,
      "step": 460
    },
    {
      "epoch": 0.6722689075630253,
      "grad_norm": 1.4715240001678467,
      "learning_rate": 2.5690010298661175e-05,
      "loss": 1.2962,
      "step": 480
    },
    {
      "epoch": 0.7002801120448179,
      "grad_norm": 1.9439901113510132,
      "learning_rate": 2.5381050463439752e-05,
      "loss": 0.8705,
      "step": 500
    },
    {
      "epoch": 0.7002801120448179,
      "eval_loss": 0.9890371561050415,
      "eval_runtime": 5.1993,
      "eval_samples_per_second": 15.387,
      "eval_steps_per_second": 1.923,
      "step": 500
    },
    {
      "epoch": 0.7282913165266106,
      "grad_norm": 1.9907991886138916,
      "learning_rate": 2.5072090628218332e-05,
      "loss": 0.8358,
      "step": 520
    },
    {
      "epoch": 0.7563025210084033,
      "grad_norm": 2.121983051300049,
      "learning_rate": 2.476313079299691e-05,
      "loss": 0.9961,
      "step": 540
    },
    {
      "epoch": 0.7843137254901961,
      "grad_norm": 1.5952779054641724,
      "learning_rate": 2.445417095777549e-05,
      "loss": 0.8384,
      "step": 560
    },
    {
      "epoch": 0.8123249299719888,
      "grad_norm": 1.6372097730636597,
      "learning_rate": 2.4145211122554067e-05,
      "loss": 0.9438,
      "step": 580
    },
    {
      "epoch": 0.8403361344537815,
      "grad_norm": 1.4837770462036133,
      "learning_rate": 2.3836251287332648e-05,
      "loss": 1.3577,
      "step": 600
    },
    {
      "epoch": 0.8403361344537815,
      "eval_loss": 0.8806487321853638,
      "eval_runtime": 5.0832,
      "eval_samples_per_second": 15.738,
      "eval_steps_per_second": 1.967,
      "step": 600
    },
    {
      "epoch": 0.8683473389355743,
      "grad_norm": 1.8774439096450806,
      "learning_rate": 2.3527291452111225e-05,
      "loss": 0.5297,
      "step": 620
    },
    {
      "epoch": 0.896358543417367,
      "grad_norm": 2.183586835861206,
      "learning_rate": 2.3218331616889805e-05,
      "loss": 0.9348,
      "step": 640
    },
    {
      "epoch": 0.9243697478991597,
      "grad_norm": 1.2063053846359253,
      "learning_rate": 2.2909371781668382e-05,
      "loss": 0.7116,
      "step": 660
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 1.4716877937316895,
      "learning_rate": 2.2600411946446963e-05,
      "loss": 0.7449,
      "step": 680
    },
    {
      "epoch": 0.9803921568627451,
      "grad_norm": 2.679044246673584,
      "learning_rate": 2.229145211122554e-05,
      "loss": 1.1237,
      "step": 700
    },
    {
      "epoch": 0.9803921568627451,
      "eval_loss": 0.8052672147750854,
      "eval_runtime": 5.1359,
      "eval_samples_per_second": 15.577,
      "eval_steps_per_second": 1.947,
      "step": 700
    },
    {
      "epoch": 1.0084033613445378,
      "grad_norm": 2.4631552696228027,
      "learning_rate": 2.198249227600412e-05,
      "loss": 0.9751,
      "step": 720
    },
    {
      "epoch": 1.0364145658263306,
      "grad_norm": 1.8558549880981445,
      "learning_rate": 2.1673532440782697e-05,
      "loss": 1.0873,
      "step": 740
    },
    {
      "epoch": 1.0644257703081232,
      "grad_norm": 2.668853521347046,
      "learning_rate": 2.1364572605561278e-05,
      "loss": 1.0094,
      "step": 760
    },
    {
      "epoch": 1.092436974789916,
      "grad_norm": 1.936310887336731,
      "learning_rate": 2.1055612770339855e-05,
      "loss": 1.0466,
      "step": 780
    },
    {
      "epoch": 1.1204481792717087,
      "grad_norm": 2.021389961242676,
      "learning_rate": 2.0746652935118436e-05,
      "loss": 0.9414,
      "step": 800
    },
    {
      "epoch": 1.1204481792717087,
      "eval_loss": 0.7522681355476379,
      "eval_runtime": 5.1546,
      "eval_samples_per_second": 15.52,
      "eval_steps_per_second": 1.94,
      "step": 800
    },
    {
      "epoch": 1.1484593837535013,
      "grad_norm": 2.725428581237793,
      "learning_rate": 2.0437693099897013e-05,
      "loss": 0.5678,
      "step": 820
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 1.9305105209350586,
      "learning_rate": 2.0128733264675593e-05,
      "loss": 0.7951,
      "step": 840
    },
    {
      "epoch": 1.2044817927170868,
      "grad_norm": 1.8481954336166382,
      "learning_rate": 1.981977342945417e-05,
      "loss": 1.0377,
      "step": 860
    },
    {
      "epoch": 1.2324929971988796,
      "grad_norm": 1.7582768201828003,
      "learning_rate": 1.951081359423275e-05,
      "loss": 0.5814,
      "step": 880
    },
    {
      "epoch": 1.2605042016806722,
      "grad_norm": 2.6928794384002686,
      "learning_rate": 1.9201853759011328e-05,
      "loss": 0.8083,
      "step": 900
    },
    {
      "epoch": 1.2605042016806722,
      "eval_loss": 0.7027579545974731,
      "eval_runtime": 5.1907,
      "eval_samples_per_second": 15.412,
      "eval_steps_per_second": 1.927,
      "step": 900
    },
    {
      "epoch": 1.2885154061624648,
      "grad_norm": 3.485405445098877,
      "learning_rate": 1.8892893923789908e-05,
      "loss": 0.8618,
      "step": 920
    },
    {
      "epoch": 1.3165266106442577,
      "grad_norm": 3.248570442199707,
      "learning_rate": 1.8583934088568485e-05,
      "loss": 0.7896,
      "step": 940
    },
    {
      "epoch": 1.3445378151260505,
      "grad_norm": 3.3449530601501465,
      "learning_rate": 1.8274974253347066e-05,
      "loss": 1.0069,
      "step": 960
    },
    {
      "epoch": 1.3725490196078431,
      "grad_norm": 2.227752447128296,
      "learning_rate": 1.7966014418125643e-05,
      "loss": 0.6328,
      "step": 980
    },
    {
      "epoch": 1.4005602240896358,
      "grad_norm": 2.918473958969116,
      "learning_rate": 1.7657054582904223e-05,
      "loss": 1.0627,
      "step": 1000
    },
    {
      "epoch": 1.4005602240896358,
      "eval_loss": 0.6717361211776733,
      "eval_runtime": 5.2074,
      "eval_samples_per_second": 15.363,
      "eval_steps_per_second": 1.92,
      "step": 1000
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 2.0127928256988525,
      "learning_rate": 1.73480947476828e-05,
      "loss": 0.799,
      "step": 1020
    },
    {
      "epoch": 1.4565826330532212,
      "grad_norm": 2.1265811920166016,
      "learning_rate": 1.703913491246138e-05,
      "loss": 0.703,
      "step": 1040
    },
    {
      "epoch": 1.484593837535014,
      "grad_norm": 2.3294601440429688,
      "learning_rate": 1.6730175077239958e-05,
      "loss": 0.3709,
      "step": 1060
    },
    {
      "epoch": 1.5126050420168067,
      "grad_norm": 2.9966721534729004,
      "learning_rate": 1.642121524201854e-05,
      "loss": 0.7854,
      "step": 1080
    },
    {
      "epoch": 1.5406162464985993,
      "grad_norm": 3.8041937351226807,
      "learning_rate": 1.6112255406797116e-05,
      "loss": 0.9604,
      "step": 1100
    },
    {
      "epoch": 1.5406162464985993,
      "eval_loss": 0.6497800946235657,
      "eval_runtime": 5.2357,
      "eval_samples_per_second": 15.28,
      "eval_steps_per_second": 1.91,
      "step": 1100
    },
    {
      "epoch": 1.5686274509803921,
      "grad_norm": 1.837398648262024,
      "learning_rate": 1.5803295571575696e-05,
      "loss": 0.8457,
      "step": 1120
    },
    {
      "epoch": 1.596638655462185,
      "grad_norm": 1.9725600481033325,
      "learning_rate": 1.5494335736354273e-05,
      "loss": 1.3267,
      "step": 1140
    },
    {
      "epoch": 1.6246498599439776,
      "grad_norm": 1.281064510345459,
      "learning_rate": 1.5185375901132854e-05,
      "loss": 0.9186,
      "step": 1160
    },
    {
      "epoch": 1.6526610644257702,
      "grad_norm": 2.449087142944336,
      "learning_rate": 1.4876416065911431e-05,
      "loss": 1.0948,
      "step": 1180
    },
    {
      "epoch": 1.680672268907563,
      "grad_norm": 2.331831693649292,
      "learning_rate": 1.456745623069001e-05,
      "loss": 0.7591,
      "step": 1200
    },
    {
      "epoch": 1.680672268907563,
      "eval_loss": 0.6332393884658813,
      "eval_runtime": 5.2295,
      "eval_samples_per_second": 15.298,
      "eval_steps_per_second": 1.912,
      "step": 1200
    },
    {
      "epoch": 1.708683473389356,
      "grad_norm": 2.079218626022339,
      "learning_rate": 1.4258496395468588e-05,
      "loss": 0.2692,
      "step": 1220
    },
    {
      "epoch": 1.7366946778711485,
      "grad_norm": 1.4960559606552124,
      "learning_rate": 1.3949536560247167e-05,
      "loss": 0.2512,
      "step": 1240
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 2.0612075328826904,
      "learning_rate": 1.3640576725025746e-05,
      "loss": 0.8229,
      "step": 1260
    },
    {
      "epoch": 1.7927170868347337,
      "grad_norm": 2.310790777206421,
      "learning_rate": 1.3331616889804325e-05,
      "loss": 0.665,
      "step": 1280
    },
    {
      "epoch": 1.8207282913165266,
      "grad_norm": 2.9621455669403076,
      "learning_rate": 1.3022657054582904e-05,
      "loss": 0.6909,
      "step": 1300
    },
    {
      "epoch": 1.8207282913165266,
      "eval_loss": 0.6200464963912964,
      "eval_runtime": 5.4014,
      "eval_samples_per_second": 14.811,
      "eval_steps_per_second": 1.851,
      "step": 1300
    },
    {
      "epoch": 1.8487394957983194,
      "grad_norm": 2.0259764194488525,
      "learning_rate": 1.2713697219361482e-05,
      "loss": 0.596,
      "step": 1320
    },
    {
      "epoch": 1.876750700280112,
      "grad_norm": 2.1578710079193115,
      "learning_rate": 1.2404737384140061e-05,
      "loss": 0.6223,
      "step": 1340
    },
    {
      "epoch": 1.9047619047619047,
      "grad_norm": 2.4553027153015137,
      "learning_rate": 1.209577754891864e-05,
      "loss": 0.6139,
      "step": 1360
    },
    {
      "epoch": 1.9327731092436975,
      "grad_norm": 3.5623514652252197,
      "learning_rate": 1.1786817713697219e-05,
      "loss": 0.8826,
      "step": 1380
    },
    {
      "epoch": 1.9607843137254903,
      "grad_norm": 2.675804615020752,
      "learning_rate": 1.14778578784758e-05,
      "loss": 0.3576,
      "step": 1400
    },
    {
      "epoch": 1.9607843137254903,
      "eval_loss": 0.6110001802444458,
      "eval_runtime": 5.4479,
      "eval_samples_per_second": 14.685,
      "eval_steps_per_second": 1.836,
      "step": 1400
    },
    {
      "epoch": 1.988795518207283,
      "grad_norm": 1.9606761932373047,
      "learning_rate": 1.1168898043254378e-05,
      "loss": 0.6003,
      "step": 1420
    },
    {
      "epoch": 2.0168067226890756,
      "grad_norm": 1.456310749053955,
      "learning_rate": 1.0859938208032957e-05,
      "loss": 0.807,
      "step": 1440
    },
    {
      "epoch": 2.044817927170868,
      "grad_norm": 3.8097922801971436,
      "learning_rate": 1.0550978372811536e-05,
      "loss": 0.59,
      "step": 1460
    },
    {
      "epoch": 2.0728291316526612,
      "grad_norm": 3.5199339389801025,
      "learning_rate": 1.0242018537590114e-05,
      "loss": 0.8894,
      "step": 1480
    },
    {
      "epoch": 2.100840336134454,
      "grad_norm": 3.2455296516418457,
      "learning_rate": 9.933058702368693e-06,
      "loss": 1.2035,
      "step": 1500
    },
    {
      "epoch": 2.100840336134454,
      "eval_loss": 0.6010088920593262,
      "eval_runtime": 5.3289,
      "eval_samples_per_second": 15.012,
      "eval_steps_per_second": 1.877,
      "step": 1500
    },
    {
      "epoch": 2.1288515406162465,
      "grad_norm": 2.3708765506744385,
      "learning_rate": 9.624098867147272e-06,
      "loss": 0.6018,
      "step": 1520
    },
    {
      "epoch": 2.156862745098039,
      "grad_norm": 3.4806034564971924,
      "learning_rate": 9.31513903192585e-06,
      "loss": 0.4938,
      "step": 1540
    },
    {
      "epoch": 2.184873949579832,
      "grad_norm": 2.2385263442993164,
      "learning_rate": 9.00617919670443e-06,
      "loss": 0.5823,
      "step": 1560
    },
    {
      "epoch": 2.212885154061625,
      "grad_norm": 2.4439830780029297,
      "learning_rate": 8.697219361483008e-06,
      "loss": 1.056,
      "step": 1580
    },
    {
      "epoch": 2.2408963585434174,
      "grad_norm": 2.4220385551452637,
      "learning_rate": 8.388259526261587e-06,
      "loss": 0.3897,
      "step": 1600
    },
    {
      "epoch": 2.2408963585434174,
      "eval_loss": 0.5933276414871216,
      "eval_runtime": 5.4484,
      "eval_samples_per_second": 14.683,
      "eval_steps_per_second": 1.835,
      "step": 1600
    },
    {
      "epoch": 2.26890756302521,
      "grad_norm": 2.5273966789245605,
      "learning_rate": 8.079299691040166e-06,
      "loss": 1.1285,
      "step": 1620
    },
    {
      "epoch": 2.2969187675070026,
      "grad_norm": 2.4843742847442627,
      "learning_rate": 7.770339855818745e-06,
      "loss": 0.9973,
      "step": 1640
    },
    {
      "epoch": 2.3249299719887957,
      "grad_norm": 2.300649404525757,
      "learning_rate": 7.461380020597322e-06,
      "loss": 0.8269,
      "step": 1660
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 4.259862422943115,
      "learning_rate": 7.152420185375901e-06,
      "loss": 0.9626,
      "step": 1680
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 3.581895112991333,
      "learning_rate": 6.8434603501544795e-06,
      "loss": 1.1868,
      "step": 1700
    },
    {
      "epoch": 2.380952380952381,
      "eval_loss": 0.5869932770729065,
      "eval_runtime": 5.459,
      "eval_samples_per_second": 14.655,
      "eval_steps_per_second": 1.832,
      "step": 1700
    },
    {
      "epoch": 2.4089635854341735,
      "grad_norm": 2.0096638202667236,
      "learning_rate": 6.534500514933058e-06,
      "loss": 0.4735,
      "step": 1720
    },
    {
      "epoch": 2.4369747899159666,
      "grad_norm": 2.36995267868042,
      "learning_rate": 6.225540679711637e-06,
      "loss": 0.4197,
      "step": 1740
    },
    {
      "epoch": 2.4649859943977592,
      "grad_norm": 4.333232402801514,
      "learning_rate": 5.916580844490216e-06,
      "loss": 0.4885,
      "step": 1760
    },
    {
      "epoch": 2.492997198879552,
      "grad_norm": 2.2942006587982178,
      "learning_rate": 5.607621009268795e-06,
      "loss": 0.7588,
      "step": 1780
    },
    {
      "epoch": 2.5210084033613445,
      "grad_norm": 4.385770797729492,
      "learning_rate": 5.2986611740473735e-06,
      "loss": 0.8779,
      "step": 1800
    },
    {
      "epoch": 2.5210084033613445,
      "eval_loss": 0.5817088484764099,
      "eval_runtime": 5.3905,
      "eval_samples_per_second": 14.841,
      "eval_steps_per_second": 1.855,
      "step": 1800
    },
    {
      "epoch": 2.549019607843137,
      "grad_norm": 2.705981731414795,
      "learning_rate": 4.989701338825952e-06,
      "loss": 0.4248,
      "step": 1820
    },
    {
      "epoch": 2.5770308123249297,
      "grad_norm": 1.8575494289398193,
      "learning_rate": 4.680741503604531e-06,
      "loss": 0.3348,
      "step": 1840
    },
    {
      "epoch": 2.6050420168067228,
      "grad_norm": 2.713653087615967,
      "learning_rate": 4.37178166838311e-06,
      "loss": 0.7579,
      "step": 1860
    },
    {
      "epoch": 2.6330532212885154,
      "grad_norm": 2.49017071723938,
      "learning_rate": 4.062821833161689e-06,
      "loss": 0.5471,
      "step": 1880
    },
    {
      "epoch": 2.661064425770308,
      "grad_norm": 1.823021411895752,
      "learning_rate": 3.7538619979402674e-06,
      "loss": 0.6516,
      "step": 1900
    },
    {
      "epoch": 2.661064425770308,
      "eval_loss": 0.5779589414596558,
      "eval_runtime": 5.4134,
      "eval_samples_per_second": 14.778,
      "eval_steps_per_second": 1.847,
      "step": 1900
    },
    {
      "epoch": 2.689075630252101,
      "grad_norm": 3.727956771850586,
      "learning_rate": 3.4449021627188466e-06,
      "loss": 0.4819,
      "step": 1920
    },
    {
      "epoch": 2.7170868347338937,
      "grad_norm": 2.5124378204345703,
      "learning_rate": 3.1359423274974254e-06,
      "loss": 0.6716,
      "step": 1940
    },
    {
      "epoch": 2.7450980392156863,
      "grad_norm": 2.214160680770874,
      "learning_rate": 2.8269824922760042e-06,
      "loss": 0.4283,
      "step": 1960
    },
    {
      "epoch": 2.773109243697479,
      "grad_norm": 2.644749641418457,
      "learning_rate": 2.518022657054583e-06,
      "loss": 0.7439,
      "step": 1980
    },
    {
      "epoch": 2.8011204481792715,
      "grad_norm": 2.159186363220215,
      "learning_rate": 2.209062821833162e-06,
      "loss": 0.9954,
      "step": 2000
    },
    {
      "epoch": 2.8011204481792715,
      "eval_loss": 0.5727424025535583,
      "eval_runtime": 5.3291,
      "eval_samples_per_second": 15.012,
      "eval_steps_per_second": 1.876,
      "step": 2000
    },
    {
      "epoch": 2.8291316526610646,
      "grad_norm": 2.2668986320495605,
      "learning_rate": 1.9001029866117404e-06,
      "loss": 0.4252,
      "step": 2020
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 2.090345621109009,
      "learning_rate": 1.5911431513903192e-06,
      "loss": 0.433,
      "step": 2040
    },
    {
      "epoch": 2.88515406162465,
      "grad_norm": 2.4217615127563477,
      "learning_rate": 1.2976313079299692e-06,
      "loss": 0.6031,
      "step": 2060
    },
    {
      "epoch": 2.9131652661064424,
      "grad_norm": 2.477161169052124,
      "learning_rate": 9.88671472708548e-07,
      "loss": 0.9159,
      "step": 2080
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 2.315152645111084,
      "learning_rate": 6.797116374871266e-07,
      "loss": 0.2696,
      "step": 2100
    },
    {
      "epoch": 2.9411764705882355,
      "eval_loss": 0.5731088519096375,
      "eval_runtime": 5.3568,
      "eval_samples_per_second": 14.934,
      "eval_steps_per_second": 1.867,
      "step": 2100
    },
    {
      "epoch": 2.969187675070028,
      "grad_norm": 3.5259146690368652,
      "learning_rate": 3.707518022657055e-07,
      "loss": 0.7554,
      "step": 2120
    },
    {
      "epoch": 2.9971988795518207,
      "grad_norm": 2.7640135288238525,
      "learning_rate": 6.179196704428425e-08,
      "loss": 0.7421,
      "step": 2140
    }
  ],
  "logging_steps": 20,
  "max_steps": 2142,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.3271430266814464e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
